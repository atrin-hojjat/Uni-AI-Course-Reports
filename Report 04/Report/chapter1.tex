\chapter{شرح مسئله و روند کار}

\section{مقدمه}
در این گزارش با استفاده از الگوریتم 
\verb;Minimax;
یک
\verb;agent;
برای بازی
\verb;Othello;
می‌سازیم.
پیاده سازی و کد در
\href{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2004/}{اینجا}
قابل مشاهده می‌باشد.
برای پیاده سازی
\verb;engine;
بازی و رابط کاربری از 
\lr{Python}
و برای پیاده سازی الگوریتم از
\lr{C++}
استفاده شده است.

\section{روش اجرا}
برای اجرای برنامه نیاز به 
\verb;Python;
با حداقل ورژن 
$3.8$
و 
\lr{gcc/g++}
با
\lr{c++17}
دارید.

برای اجرای برنامه ابتدا نیاز به راه اندازی یک
\lr{Virtual environment}
برای 
\verb;Python;
است.
به این منظور در فولدر
\lr{Report 04/game}
دستورات زیر را اجرا کنید.

\lstset{language=bash}
\begin{latin}
\begin{lstlisting}
cd Report\\ 04/game
python3 -m venv venv
\end{lstlisting}
\end{latin}

برای 
\verb;activate;
کردن با توجه به سیتم عامل دستورات
\href{https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/}{اینجا}
\footnote{برای جزئیات بیشتر به 
\href{https://docs.python.org/3/library/venv.html}{اینجا}
 مراجعه کنید
 }
را اجرا کنید.

برای نصب پیشنیاز ها دستورات زیر را اجرا کنید.

\begin{latin}
\begin{lstlisting}
python3 -m pip install -r requirements.txt
\end{lstlisting}
\end{latin}

برای اضافه کردن ماژول 
\verb;Minimax;
باید کد 
\lr{c++}
الگوریتم به ماژول 
\lr{Python}
تبدیل شود.

\begin{latin}
\begin{lstlisting}
cd agent/MiniMaxCompEngine
python3 setup.py build
python3 setup.py install
cd ../../
\end{lstlisting}
\end{latin}

سپس با اجرای فایل
\lr{test01.py}
قادر به اجرای برنامه خواهید بود.

\begin{latin}
\begin{lstlisting}
python3 test01.py
\end{lstlisting}
\end{latin}

\chapter{پیاده‌سازی رابط کاربری و \lr{\ttfamily{Engine}} بازی}
\section{\lr{\ttfamily{Engine}}}
کلاس
\verb;Engine;
مسئولیت نگهداری موقعییت بازی را بر عهده دارد.
اعزای این کلاس شامل
\lr{boardSize, state, hisotry, availableMoves}
و توابع
\lr{getAvailableMoves, makeMove}
می‌باشد.
\lr{state}
یک
\lr{dict}
شامل موقعیت کنونی بازی، امتیاز هر بازیکن، آخرین بازی کنی که حرکت کرده و  اطلاعات پایان بازی می‌باشد.
\lr{history}
یک لیست از موقعیت ها‌ی کذشته و حرکات انجام شده است.

\subsection{تابع \lr{\ttfamily{getAvailableMoves}}}

تابع 
\lr{getAvailableMoves()}
با حرکت روی تمام خانه‌های خالی، چک می‌کند که اگر بازی‌کن کنونی این نقطه را انتخاب کند رنگ حداقل یک خانه‌ی همسایه تغییر می‌کند یا نه.
سپس لیستی از حرکات ممکن بر‌میگرداند.

\begin{latin}
\begin{python}
    def getAvailableMoves(self):
        if self.availableMoves:
            return [tuple(i) for i in self.availableMoves]
        curPlayer = (PLAYERS.BLACK if 
                self.state['lastPlayer'] == PLAYERS.WHITE else PLAYERS.WHITE)
        availableMoves = []
        
        for i in range(self.boardSize):
            for j in range(self.boardSize):
                if self.state['board'][i][j] != PLAYERS.NONE:
                    continue
                # Horizontal
                ok = False
                for jp in range(j + 1, self.boardSize):
                    if self.state['board'][i][jp] == PLAYERS.NONE:
                        break
                    elif self.state['board'][i][jp] == curPlayer:
                        ok = jp > j + 1
                        break

                if ok:
                    availableMoves.append((i, j))
                    continue
                for jp in range(j - 1, -1, -1):
                    if self.state['board'][i][jp] == PLAYERS.NONE:
                        break
                    elif self.state['board'][i][jp] == curPlayer:
                        ok = jp < j - 1
                        break
                if ok:
                    availableMoves.append((i, j))
                    continue


                # Vertical
                for ip in range(i + 1, self.boardSize):
                    if self.state['board'][ip][j] == PLAYERS.NONE:
                        break
                    elif self.state['board'][ip][j] == curPlayer:
                        ok = ip > i + 1
                        break
                if ok:
                    availableMoves.append((i, j))
                    continue
                for ip in range(i - 1, -1, -1):
                    if self.state['board'][ip][j] == PLAYERS.NONE:
                        break
                    elif self.state['board'][ip][j] == curPlayer:
                        ok = ip < i - 1
                        break
                if ok:
                    availableMoves.append((i, j))
                    continue

                # Diagonal
                for idel in range(-1, 2, 2):
                    for jdel in range(-1, 2, 2):
                        for k in range(1, self.boardSize):
                            if i + idel * k >= self.boardSize or i + idel * k < 0:
                                break
                            if j + jdel * k >= self.boardSize or j + jdel * k < 0:
                                break
                            ip, jp = i + idel * k, j + jdel * k
                            if self.state['board'][ip][jp] == PLAYERS.NONE:
                                break
                            elif self.state['board'][ip][jp] == curPlayer:
                                ok = k > 1
                                break
                        if ok: break
                    if ok: break
                if ok:
                    availableMoves.append((i, j))
                    continue

        self.availableMoves = [tuple(i) for i in availableMoves]
        return availableMoves


\end{python}
\end{latin}

\subsection{تابع \lr{\ttfamily{makeMove}}}

تابع
\lr{makeMove}
اندیس از خروجی
\lr{getAvailableMoves}
در‌یافت می‌کند و آن حرکت را برای بازی‌کن کنونی انجام می‌دهد.
سپس  چک می‌کند که آیا بازی به اتمام رسیده و آیا رقیب حرکت مجازی دارد یا نه و
اگر حریف حرکت مجازی نداشت نوبت را به  همان‌بازیکن بر ‌میگرداند.

\begin{latin}
\begin{python}
    def makeMove(self, move):
        if self.state['gameEnded']:
            return False
        if move not in self.availableMoves:
            return False
        self.history.append({'move': move, 'board': self.state['board']})
        board = np.copy(self.state['board'])
        self.state['board'] = board
        curPlayer = (PLAYERS.BLACK if 
                self.state['lastPlayer'] == PLAYERS.WHITE else PLAYERS.WHITE)
        self.state['lastPlayer'] = curPlayer

        i, j = move
        board[i][j] = curPlayer
        for jp in range(j + 1, self.boardSize):
            if self.state['board'][i][jp] == PLAYERS.NONE:
                break
            elif self.state['board'][i][jp] == curPlayer:
                for t in range(j + 1, jp):
                    self.state['board'][i][t] = curPlayer
                break

        for jp in range(j - 1, -1, -1):
            if self.state['board'][i][jp] == PLAYERS.NONE:
                break
            elif self.state['board'][i][jp] == curPlayer:
                for t in range(j - 1, jp, -1):
                    self.state['board'][i][t] = curPlayer
                break


        # Vertical
        for ip in range(i + 1, self.boardSize):
            if self.state['board'][ip][j] == PLAYERS.NONE:
                break
            elif self.state['board'][ip][j] == curPlayer:
                for t in range(i + 1, ip):
                    self.state['board'][t][j] = curPlayer
                break
        for ip in range(i - 1, -1, -1):
            if self.state['board'][ip][j] == PLAYERS.NONE:
                break
            elif self.state['board'][ip][j] == curPlayer:
                for t in range(i - 1, ip, -1):
                    self.state['board'][t][j] = curPlayer
                ok = ip < i - 1
                break

        # Diagonal
        for idel in range(-1, 2, 2):
            for jdel in range(-1, 2, 2):
                for k in range(1, self.boardSize):
                    if i + idel * k >= self.boardSize or i + idel * k < 0:
                        break
                    if j + jdel * k >= self.boardSize or j + jdel * k < 0:
                        break
                    ip, jp = i + idel * k, j + jdel * k
                    if self.state['board'][ip][jp] == PLAYERS.NONE:
                        break
                    elif self.state['board'][ip][jp] == curPlayer:
                        for kp in range(1, k):
                            self.state['board'][i + idel * kp][j + jdel * kp] = curPlayer
                        break
        self.availableMoves = None
        t = self.getAvailableMoves()
        
        ongoing = False
        blackScore, whiteScore = 0, 0
        for ix, iy in np.ndindex((self.boardSize, self.boardSize)):
            if self.state['board'][ix, iy] == PLAYERS.NONE:
                ongoing = True
            elif self.state['board'][ix, iy] == PLAYERS.WHITE:
                whiteScore = whiteScore + 1
            elif self.state['board'][ix, iy] == PLAYERS.BLACK:
                blackScore = blackScore + 1
        self.state['score']['black'], self.state['score']['white'] = blackScore, whiteScore
        if not ongoing or blackScore == 0 or whiteScore == 0:
            self.state['gameEnded'] = True

        if ongoing and len(t) == 0:
            # Skip One Move
            curPlayer = (PLAYERS.BLACK if 
                    self.state['lastPlayer'] == PLAYERS.WHITE else PLAYERS.WHITE)

            self.history.append({'move': None, 'board': np.copy(self.state['board'])})
            self.state['lastPlayer'] = curPlayer

        return True

\end{python}
\end{latin}

\section{رابط کاربری \lr{\ttfamily{CLI}}}
برای پیاده سازی 
\lr{\ttfamily{CLI}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2004/game/interface/CLI.py}}
از کتابخانه
\lr{\ttfamily{Rich}}
\LTRfootnote{\url{https://github.com/willmcgugan/rich}}
استفاده شده که مسئولیت نشان دادن جدول و خروجی برنامه است.
با اجرای این  کد، کاربر ابتدا باید سایز برد و دو 
\verb;agent;
انتخاب کند.
\verb;agent;
ها شامل کاربر و 
\verb;Minimax;
با عمق‌های متفاوت است.
سپس تا زمانی که بازی تمام نشده با توجه به موقعیت
\verb;engine;
به یک بازیکن اجازه‌ی حرکت می‌دهد.

\section{\lr{\ttfamily{Agent}} ها}
هر
\verb;Agent;
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/tree/main/Report\%2004/game/agent}}
یک زیرکلاس
\verb;AbstractAgent;
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2004/game/agent/Agent.py}}
با دو تابع
\lr{\ttfamily{\_\_init\_\_(self, color)}}
و 
\lr{\ttfamily{move(self, engine)}}
می‌باشد.
به فراخوانی تابع 
\verb;move;
،
یک اندیس از
\lr{\ttfamily{engine.getAvailableMoves}}
باید بازگردانده شود.

\begin{latin}
\begin{python}
class AbstractAgent:
    def __init__(self, color):
        self.color = color
    
    def move(self, engine):
        pass

\end{python}
\end{latin}

\subsection{\lr{\ttfamily{Human Agent}}}
کلاس
\lr{\ttfamily{Human Agent}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2004/game/agent/Human.py}}
در هر حرکت یک
\lr{\ttfamily{prompt}}
به کاربر نشان داده  و شماره‌ی حرکت را از کاربر می‌پرسد.
حرکت‌های ممکن و شماره‌هایشان در جدول نشان داده‌می‌شود.

\begin{latin}
\begin{python}
from . import Agent
from rich.prompt import IntPrompt
from engine.OthelloEngine import PLAYERS

class HumanAgent(Agent.AbstractAgent):
    def __init__(self, color):
        self.color = color
        self.colorName = "Black" if PLAYERS.BLACK == color else "White"

    def move(self, engine):
        moveNo = IntPrompt.ask(f"{self.colorName} to move")
        return moveNo

\end{python}
\end{latin}

\subsection{\lr{\ttfamily{Minimax Agent}}}
کلاس
\lr{\ttfamily{MiniMaxAgent}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2004/game/agent/MiniMax.py}}
در ابتدا رنگ و عمق لازم را دریافت می‌کند.
سپس برای هر حرکت موقعیت بازی را به  تابع
\lr{\ttfamily{calculateMiniMax}}
از ماژول
\lr{\ttfamily{MiniMax}}
که به زبان
\lr{\ttfamily{C++}}
نوشته شده،
ارسال می‌کند تا بهترین حرکت محاسبه شود.
موقعیت بازی باید فرمت
\lr{\ttfamily{int32\_t}}
در
\lr{\ttfamily{C++}}
داشته باشد تا اطلاعات درست
\lr{\ttfamily{parse}}
شوند.

\begin{latin}
\begin{python}
from . import Agent
from rich.prompt import IntPrompt
from engine.OthelloEngine import PLAYERS
import numpy as np
from numpy.ctypeslib import ndpointer
from MiniMax import calculateMiniMax

class MiniMaxAgent(Agent.AbstractAgent):
    depth = 7
    def __init__(self, color, depth=7):
        self.color = color
        self.colorName = "Black" if PLAYERS.BLACK == color else "White"
        self.depth = depth


    def move(self, engine):
        grid = np.copy(engine.state['board'].astype(np.int32))
        N = engine.boardSize

        result = calculateMiniMax(N, grid, self.color,
                self.depth)

        return engine.getAvailableMoves().index(result['move'])
        

\end{python}
\end{latin}

\subsection{رجیستر کردن \lr{\ttfamily{agent}}ها }

در فایل
\lr{\ttfamily{agent/\_\_init\_\_.py}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2004/game/agent/__init__.py}}
یک لیست از 
\lr{\ttfamily{Agent}}
های موجود برای صحولت کار
\lr{\ttfamily{CLI}}
نگه داشته می‌شود.
این لیست شامل یک
\lr{\ttfamily{Human Agent}}
و 
یازده
\lr{\ttfamily{MiniMax Agent}}
با عمق‌های متفاوت می‌باشد.

\begin{latin}
\begin{python}
from . import Human, MiniMax


AGENTS = [
        ("Human", Human.HumanAgent), 
        ("MiniMax agent(depth 2)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=2)),
        ("MiniMax agent(depth 3)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=3)),
        ("MiniMax agent(depth 4)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=4)),
        ("MiniMax agent(depth 5)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=5)),
        ("MiniMax agent(depth 6)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=6)),
        ("MiniMax agent(depth 7)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=7)),
        ("MiniMax agent(depth 8)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=8)),
        ("MiniMax agent(depth 9)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=9)),
        ("MiniMax agent(depth 10)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=10)),
        ("MiniMax agent(depth 11 - up to 10 seconds)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=11)),
        ("MiniMax agent(depth 12 - up to 100 seconds)", lambda col: MiniMax.MiniMaxAgent(color=col,
            depth=12)),
        ]

\end{python}
\end{latin}


\chapter{پیاده‌سازی الگوریتم \lr{\ttfamily{Minimax}}}

