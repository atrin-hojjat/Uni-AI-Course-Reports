\chapter{شرح مسئله و روند کار}

\section{مقدمه}
مسئله مجموعه‌ی غالب مسئله انتخاب رئوسی از گراف است بطوری که هر راس یا انتخاب شده باشد یا همسایه‌ای انتخاب‌شده داشته باشد. این مسئله
\lr{NP Complete}
و دارای  الگوریتم تخمین می‌باشد.
این مسئله دارای کاربردهای بسیاری در زمینه‌هایی
 مانند تئوری شبکه‌های اجتماعی
\LTRfootnote{Social network theory}
 ، شبکه‌های ارتباطی کامپیوتر‌ها
\LTRfootnote{Computer communication network}
 ، شبکه‌های بیسیم ادهاک
\LTRfootnote{Mobile Ad-hoc network - MANET}
  و شبکه‌های حسگر بیسیم
\LTRfootnote{Wireless sensor network - WSN}
می‌باشد.
\cite{sasireka2014applications}

در این گزارش این این مسئله را با استفاده از راه‌حل‌های 
\lr{Heuristic}
حل خواهیم کرد.

\section{کدها و خروجی‌های برنامه}
تمام کد‌ها و خروجی‌ها (از جمله کد
\verb;latex;
)
در
\href{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2002/}{اینجا}
قابل مشاهده می‌باشد.

\chapter{توابع ابتدایی}
\section{تولید گراف تصادفی}
برای تولید گراف تصادفی دو تابع مورد استفاده قرار گرفته است.
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2002/Problem\%2001\%20-\%20Dominating\%20Set/generators/__init__.py}}
تابع
\verb;gen_graph_eq_prob_edges;
گرافی با
$nodes$
راس تولید میکند که هر یال با احتمال
$p$
در آن حضور دارد.
\begin{latin}
\begin{python}
def gen_graph_eq_prob_edges(nodes=100, p=0.1):
    """
    Generates a graph with $nodes vertices where each edge has a $p probibility of existing. 
    The graph is represented by a list of vertices each represented as a list of vertices it's connected to.
    O(nodes ^ 2)
    """
    graph = [[] for i in range(nodes)]

    for i in range(nodes):
        for j in range(i):
            if random.random() < p:
                graph[i].append(j)
                graph[j].append(i)
    return graph

\end{python}
\end{latin}

تابع
\verb;gen_graph_fix_set_edges;
گرافی با
$nodes$
راس و  
$edges$
یال تصادفی می‌کند.

\begin{latin}
\begin{python}
def gen_graph_fix_set_edges(nodes=100, edges=900):
    """
    Generates a graph with $nodes vertices and $edges edges
    The graph is represented by a list of vertices each represented as a list of vertices it's connected to.
    O(nodes ^ 2)
    """
    graph = [[] for i in range(nodes)]

    all_edges = []
    
    for i in range(nodes):
        for j in range(i):
            all_edges.append((i, j, ))

    for i in range(edges):
        x = random.randrange(0, len(all_edges))
        edge = all_edges[x]
        graph[edge[0]].append(edge[1])
        graph[edge[1]].append(edge[0])
        all_edges.pop(x)

    return graph

\end{python}
\end{latin}

\section{بررسی هدف}
تابع
\lr{utils}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2002/Problem\%2001\%20-\%20Dominating\%20Set/solutions/utils.py}}
در 
\lr{solutions}
 روی تمام یال ‌های رئوس انتخاب شده می‌گردد  و رئوس دیده‌شده را علامت می‌زند.
 زمان اجرای این تابع
 $O(EV)$
 و حافظه‌ی آن
 $O(V)$
  می‌باشد.
 به دلیل محدود بودن کل عملایات های چک کردن حالت بهینه به
 $NP$
 برای بهینه‌سازی این توابع تلاشی نشده‌است.
 
\begin{latin}
\begin{python}
import math
import heapq
import random

def is_goal(graph, state):
    ls = {}
    for i in range(len(graph)):
        ls[i] = ""
    for v in state:
        if v in ls:
            del ls[v]
        for u in graph[v]:
            if u in ls:
                del ls[u]
    return len(ls) == 0, [*ls.keys()], ls

 \end{python}
 \end{latin}

 
 \section{تصویر سازی}
 برای نمایش دادن نمودارهای برنامه از
\verb;matplotlib;
\LTRfootnote{\url{https://matplotlib.org/}}
 و برای گراف‌ها از
\verb;networkx;
\LTRfootnote{\url{https://networkx.org/documentation/stable/}}
استفاده شده.
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/tree/main/Report\%2002/Problem\%2001\%20-\%20Dominating\%20Set/visualizers}}
 
\chapter{الگوریتم‌ها}
\section{$A*$}
\lr{A*}
\LTRfootnote{\url{https://en.wikipedia.org/wiki/A*_search_algorithm}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2002/Problem\%2001\%20-\%20Dominating\%20Set/solutions/AStar.py}}
نوعی خاصی از
\lr{Best-first search}
است که در تابع تخمین وزن، وزن مسیر تا آن لحظه نیز محاسبه می‌شود.
\subsection{تخمین و روش محاسبه}
فرض کنید
 $G$
 گراف مورد نظر ما باشد.
 در حالتی که در آن مجموعه
 ‌$C={v_{1},... v_{t}}$
  انتخاب شده‌اند
برای محاسبه تابع 
\lr{Heuristic}
از فرمول
\begin{equation}
\label{e01}
h(C) = \frac{n(G - C - nei(C))}{\max\limits_{v \in {G - C - nei(C)}} {deg_{G - C - nei(C)}(v) + 1}}
\end{equation}
\begin{equation}
\label{e02}
f(C) = h(C) + n(C)
\end{equation}
استفاده میکنیم
\subsection{بررسی \lr{\ttfamily{Admissibility}}\label{AS_ADMISSIBLE}}
به وضوح، انتخاب هر راس انتخاب نشده حداکثر به اندازه‌ی درجه‌اش در گراف باقی مانده، راس جدید را پوشش میدهد. درنتیجه اگر درجه‌ی همه‌ی رئوسی که از این نقطه انتخاب می‌کنیم، برابر حداکثر درجه‌ی گراف باقی مانده باشد و هیچ راسی را دوبار پوشش ندهیم،
$h(C)$
راس دیگر باید انتخاب شود تا همه‌ی رئوس گراف پوشیده شده‌باشد.
 پس بوضوح داریم :
\begin{equation}
\label{e03}
h(C) \leq h^*(C)
\end{equation}
یعنی تابع هیوریستیکمان 
\lr{Admissible}
می‌باشد پس می‌توان نتیجه گرفت که 
\lr{A*}
جواب بهینه می‌دهد و درنتیجه 
‌‌$NP$
است.

\subsection{نمونه ها}
خروجی الگوریتم برای
$N=20$
و 
$P=0.2$
(
\cref{AS_S_02_20})
،
$P=0.3$
(
\cref{AS_S_03_20})
،
و
$P=0.12$
(
\cref{AS_S_012_20})
نشان داده شده است
.

\insertfig{figures/A* Results graph 20-0.2.pgf}{\lr{A* on $N=20, P=0.2$}}{AS_S_02_20}
\insertfig{figures/A* Results graph 20-0.3.pgf}{\lr{A* on $N=20, P=0.3$}}{AS_S_03_20}
\insertfig{figures/A* Results graph 20-0.12.pgf}{\lr{A* on $N=20, P=0.12$}}{AS_S_012_20}


\section{\lr{\ttfamily{Greedy best-first search}}}
برای این الگوریتم
\LTRfootnote{\url{https://en.wikipedia.org/wiki/Best-first_search}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2002/Problem\%2001\%20-\%20Dominating\%20Set/solutions/GreedyBestFirst.py}}
 نیز از همان تابع هیوریستیکی که در بالا استفاده شد استفاده میکنیم و پیاده سازی این الگوریتم کاملا مشابه 
$A*$
است البته هزینه‌ی صرف شده تا این نقطه را در نظر نمی‌گیریم یعنی:
\begin{equation}
\label{e04}
f(C)=h(C)
\end{equation}


\subsection{نمونه ها}
خروجی الگوریتم برای
$N=20$
و 
$P=0.2$
(
\cref{GB_S_02_20})
،
$P=0.3$
(
\cref{GB_S_03_20})
،
و
$P=0.12$
(
\cref{GB_S_012_20})
نشان داده شده است
.

\insertfig{figures/Greedy best-first search Results graph 20-0.2.pgf}{\lr{Greedy best-first on $N=20, P=0.2$}}{GB_S_02_20}
\insertfig{figures/Greedy best-first search Results graph 20-0.3.pgf}{\lr{Greedy best-first on $N=20, P=0.3$}}{GB_S_03_20}
\insertfig{figures/Greedy best-first search Results graph 20-0.12.pgf}{\lr{Greedy best-first on $N=20, P=0.12$}}{GB_S_012_20}



\section{\lr{\ttfamily{Hill-climbing}}}
این الگوریتم
\LTRfootnote{\url{https://en.wikipedia.org/wiki/Hill_climbing}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2002/Problem\%2001\%20-\%20Dominating\%20Set/solutions/HillClimbing.py}}
 بالا رفتن از یک تپه را شبیه‌سازی می‌کند.
\subsection{تابع تخمین ارزش}
مقدار این تابع باید طوری باشد که با افزایش راس‌های پوشش یافته زیاد شود و با افزایش تعداد رئوس انتخاب‌شده کاهش یابد.
اگر ضریب این دو مقدار برابر باشند یعنی تابع به فرم
$-|C| -|G - C - nei(C)| $
باشد، الگوریتم لزومی در انتخاب یال‌های بدیهی نخواهد داشت.
برای همین ضریب 
$|G - C - nei(C)|$
را 
$-2$
قرار دادیم و برای مثبت نگه داشتن کل عبارت را با
$2|G|$
جمع کردیم.
پس تابع به فرم
\begin{equation}
\label{e01}
E(C) = 2 |G| - 2 |G - C - nei(C)| - |C|
\end{equation}
خواهد بود.
\subsection{همسایگی}
دو حالت را همسایه میگوییم هرگاه یکی با حذف دقیقا یک عضو به دیگری تبدیل شود.

\subsection{شروع تصادفی}
برای افزایش احتمال پیدا کردن جواب درست میتوانیم بجای شروع از مجموعه خالی، از مجموعه‌ای از اعضای تصادفی انتخاب شده استفاده کنیم بطوری که احتمال حضور هر یک از آن‌ها در مجموعه‌ی اولیهبرابر متغییر
\ttfamily{rand\_start}
\rmfamily
باشد.

\subsection{نمونه ها}

خروجی الگوریتم برای
$N=20$
و 
$P=0.2$
(
\cref{HC_S_02_20})
،
$P=0.3$
(
\cref{HC_S_03_20})
،
و
$P=0.12$
(
\cref{HC_S_012_20})
نشان داده شده است
.

\insertfig{figures/Hill-climbing Results graph 20-0.2.pgf}{\lr{Hill-climbing on $N=20, P=0.2$}}{HC_S_02_20}
\insertfig{figures/Hill-climbing Results graph 20-0.3.pgf}{\lr{Hill-climbing on $N=20, P=0.3$}}{HC_S_03_20}
\insertfig{figures/Hill-climbing Results graph 20-0.12.pgf}{\lr{Hill-climbing on $N=20, P=0.12$}}{HC_S_012_20}


\section{\lr{\ttfamily{Annealing Search}}}
برای پیاده سازی این الگوریتم
\LTRfootnote{\url{https://en.wikipedia.org/wiki/Simulated_annealing}}
\LTRfootnote{\url{https://github.com/atrin-hojjat/Uni-AI-Course-Reports/blob/main/Report\%2002/Problem\%2001\%20-\%20Dominating\%20Set/solutions/AnnealingSearch.py}}
 از تابع ارزش‌گذاری مانند بالا استفاده میکنیم. تغییرات دما به فرم 
$T_{next}=0.98 T_{now}$
با حداقل دمای  $0.000001$ و دمای اولیه 1 ثبت شده‌اند.

\subsection{نمونه ها}

خروجی الگوریتم برای
$N=20$
و 
$P=0.2$
(
\cref{ANS_S_02_20})
،
$P=0.3$
(
\cref{ANS_S_03_20})
،
و
$P=0.12$
(
\cref{ANS_S_012_20})
نشان داده شده است
.

\insertfig{figures/Annealing Search Results graph 20-0.2.pgf}{\lr{Annealing on $N=20, P=0.2$}}{ANS_S_02_20}
\insertfig{figures/Annealing Search Results graph 20-0.3.pgf}{\lr{Annealing on $N=20, P=0.3$}}{ANS_S_03_20}
\insertfig{figures/Annealing Search Results graph 20-0.12.pgf}{\lr{Annealing on $N=20, P=0.12$}}{ANS_S_012_20}


\chapter{مقایسه روش‌های متفاوت}
\section{تست‌ها و روش اندازه‌گیری}
برای مقایسه‌ی روش‌های استفاده شده از دو تابع 

\begin{latin}
\begin{python}
def TestBy(start, end, diff, tries, nodes):
	pass
def TestByN(start, end, diff, tries, p):
	pass
\end{python}
\end{latin}

استفاده شده است. تابع
\verb;TestByP;
به ازای همه‌ی مقادیر
$start\leq P < end$
با قدم‌هایی به اندازه‌ی 
$diff$
،هر چهار الگوریتم را 
\verb;tries;
بار روی  یک گراف جدید که با تابع 
\verb;gen_graph_eq_prob_edges;
به دست آمده‌اند اجرا کرده و  جواب‌ها و تعداد تکرار‌ها را مقایسه می‌کند.
تابع 
\verb;TestByN;
نیز با تغییر 
$N$
روند مشابهی را طی می‌کند.
سپس هردوی این توابع، تعداد تکرارها، درصد موفقیت(پیدا کردن کمترین پاسخ صحیح) و تختلاف هریک با کمترین پاسخ صحیح را نمایش می‌دهند.
\footnote{خروجی در $output/TestBy[N,P]$ ذخیره می‌شود}

مقادیر ورودی این توابع در تست‌ها به شکل زیر می‌باشند:
\begin{latin}
\begin{python}
TestByP(start=0.12, end=.36, diff=0.04, tries=10, nodes=20)
TestByN(start=5, end=25, diff=2, tries=10, p=0.2)
\end{python}
\end{latin}


\section{مقایسه‌ی تعداد تکرارها}
الگوریتم 
$A*$
و
\lr{\ttfamily{Greedy best-frist search}}
به ترتیب بیشترین تعداد تکرار‌ها با کاهش 
$P$
را داشتند اما
$Annealing$
و
$Hill-climbing$
با افزایش 
$N$
و
$P$
تغییر چندانی نداشتند.
با نزدیک شدن به 
$P=0.24$
تعداد تکرارهای
$A*$
از
$Annealing$
کمتر شد و با نزدیک شدن به
$P=0.3$
به تعداد تکرار‌ها به تکرارهای الگوریتم
$Hill-climbing$
رسید.
(
\cref{TBP_ITS}
)

در
$N$
های کوچک الگوریتم
$Annealing$
به مراتب به تکرارهای بیشتری از بقیه نیاز دارد اما با افزایش
$N$
،
 الگوریتم‌های دیگر به میزان تکرار‌های بیشتری نیاز پیدا می‌کنند،
 الگوریتم
$A*$
با افزایش نمایی
 در حدود
$N=16$
و 
\lr{\ttfamily{Greedy best-first search}}
در حدود
$23\leq N \leq 25$
.
(
\cref{TBN_ITS}
)
\insertfig{figures/TestByN/Test number of iterations by N.pgf}{تعداد تکرار‌های برنامه با افزایش تعداد رئوس}{TBN_ITS}
\insertfig{figures/TestByP/Test number of iterations by edge existance possibility.pgf}{تعداد تکرار‌های برنامه با افزایش احتمال وجود هر یال}{TBP_ITS}

\section{مقایسه صحت}
همانطوری که در
\cref{AS_ADMISSIBLE}
بررسی شد، الگوریتم
$A*$
همواره جواب بهینه را پیدا می‌کند.

الگوریتم
\lr{\ttfamily{Greedy best-first search}}
با تغییر
$P$
تغییر چندانی نمی‌کند و حدود ۳۰ تا ۴۰ درطد مواقع جواب بهینه را می‌دهد و بین ۷۰ تا ۸۰ درصد مواقع حاکثر سه راس بیشتر از 
$A*$
انتخاب می‌کند. از طرفی در 
$N\leq10$
همواره جواب بهینه می‌دهد و  با افزایش 
$N$
افت شدیدی در دقت آن مشاهده می‌شود.

الگوریتم
\verb;Annealing;
در 
$P$
های کوچک  درصد موفقیت بیشتر   و تعداد بیشتری جواب با اختلاف حداکثر ۳ با  بهترین جواب 
در مقایسه به
\lr{\ttfamily{Greedy best-first search}}
دارد.
با افزایش 
$P$
اختلاف درصد موفقییت ناچیز می‌شود اما تعداد جواب ها با اختلاف حداکثر ۳ از جواب بهینه، اگرچه کم می‌شود اما هنوز وجود دارد.
در 
$N$
های کوچک 
\lr{\ttfamily{Greedy best-first search}}
عملکرد بهتری در هر دو زمینه نشان می‌دهد و از حدود
$N=11$
دقت و صحت
$Annealing$
بیشتر می‌شود.

الگوریتم
\lr{\ttfamily{Hill-climbing}}
نزدیک‌ترین جواب به جواب بهینه را می‌دهد و با تغییر
$N$
و
$P$
همواره دقت و صحت بیشتری از
\lr{\ttfamily{Greedy best-first search}}
و
\verb;Annealing;
دارد.

\insertfig{figures/TestByP/Test success rate by edge existance possibility.pgf}{درصد یافتن جواب درست با افزایش احتمال وجود هر یال}{TBP_P}

\insertfig{figures/TestByP/Distance from best answer.pgf}{اختلاف تعداد رئوس با بهترین جواب با تافزایش احتمال وجود هر یال}{TBP_D}

\insertfig{figures/TestByN/Test success rate by N.pgf}{درصد یافتن جواب درست با افزایش تعداد رئوس}{TBN_P}

\insertfig{figures/TestByN/Distance from best answer.pgf}{اختلاف تعداد رئوس با بهترین جواب با افزایش تعداد رئوس}{TBN_D}

